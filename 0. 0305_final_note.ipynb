{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9-Z82i495Gl"
   },
   "source": [
    "#       Seq2Seq: Text Summarization with Keras\n",
    "![](http://abigailsee.com/img/pointer-gen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pw_oyfrE95Go"
   },
   "source": [
    "## Process\n",
    "1. Preprocessing\n",
    "2. Word2vec\n",
    "3. Building Seq2Seq Architecture\n",
    "4. Training with  BBC article&summary Dataset\n",
    "5. Generate Summary with my_summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2QnkkQv95Gq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QeKq5tai95Gu"
   },
   "outputs": [],
   "source": [
    "news_category = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
    "\n",
    "row_doc = \"/Users/akr712/Desktop/Text_Summarization_using_Keras/Row News Articles/\"\n",
    "summary_doc = \"/Users/akr712/Desktop/Text_Summarization_using_Keras/Summaries/\"\n",
    "\n",
    "data={\"articles\":[], \"summaries\":[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlcQJpw-95Gx"
   },
   "source": [
    "DataFrameを作る\n",
    "- テキストファイル名を取得\n",
    "- テキストファイルの中身を取得\n",
    "- データフレーム化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "682uVCoC95Gy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directories = {\"news\": row_doc, \"summary\": summary_doc}\n",
    "row_dict = {}\n",
    "sum_dict = {}\n",
    "\n",
    "for path in directories.values():\n",
    "    if path == row_doc:\n",
    "        file_dict = row_dict\n",
    "    else:\n",
    "        file_dict = sum_dict\n",
    "    dire = path\n",
    "    for cat in news_category:\n",
    "        category = cat\n",
    "        files = os.listdir(dire + category)\n",
    "        file_dict[cat] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8u0FGyc95G1",
    "outputId": "34947867-c0bb-4b6a-ee14-9c3dcc7f1558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['politics', 'sport', 'business', 'tech', 'entertainment'])"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jB61vhEN95G9",
    "outputId": "8ac16624-7e66-4843-9ee3-639b2b6bc5f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"001.txt\" in row_dict['politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMPGUVug95HE",
    "outputId": "aefeb0c6-05bc-4a31-9244-2b00fbd45639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file read successfully\n"
     ]
    }
   ],
   "source": [
    "text = parsetext(row_doc, \"sport\", \"291.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1LKDywA95HK",
    "outputId": "c938c3bf-eb6a-4fed-cb9b-5e119914949c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thomas out of six nations\\n\\nwales captain gareth thomas has been ruled out of the rest of the six nations with a broken thumb.\\n\\nthe full-back will have surgery on monday after fracturing his thumb in the 24-18 win over france on saturday. but welsh legend phil bennett insisted wales can cope without thomas as they chase a first grand slam in 27 years. bennett told bbc sport: \"such is the spirit in the camp, they\\'ll put kevin morgan at 15, rhys williams at wing and just carry on.\" thomas will miss the match against scotland on 13 march, and what promises to be a huge encounter against the irish six days later. bennett added: \"it\\'s a setback. he\\'s a great captain, he leads from the front and the boys love him.\" thomas was replaced at half-time by williams as his side turned around a 15-6 deficit in paris.\\n\\n\"with gareth missing i would think michael owen will be our captain,\" said wales coach mike ruddock. \"he did a great job in the second half in france. he has been vice-captain all along throughout the championship.\" wales travel to edinburgh to take on scotland in a fortnight and then host ireland in cardiff in the final round of matches in what could be the grand slam and championship decider. bennett, an inspirational fly-half for llanelli and wales in the 1970s, insisted the national team were entering a new golden period. \"it was a great game and a magnificent result for wales,\" bennett told bbc radio five live\\'s sportsweek programme.\\n\\n\"the way this young team are blending, the glory days are on their way back. \"we couldn\\'t get possession early on and france dominated and scored two tries. \"had they been ruthless, wales could have gone into the interval 30 points down. but they didn\\'t take their chances. \"wales defended fairly well but you cannot give that sort of quality ball to good sides. \"the all blacks would have been ruthless and buried us in the first half. but the character we showed in the second half was quite outstanding.\"\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkgkPijt95HO"
   },
   "outputs": [],
   "source": [
    "for name in row_dict[\"politics\"]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBp9A95t95HS",
    "outputId": "3b4f15ad-d742-412d-896a-66a9082720e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'289.txt'"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_dict[\"sport\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anZi-hCB95HY",
    "outputId": "e4cd1937-f843-423c-d0ad-7834ff1e5d38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(row_dict[\"sport\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gM75fs9g95Hc"
   },
   "outputs": [],
   "source": [
    "row_data = {}\n",
    "for cat in row_dict.keys():\n",
    "    cat_dict = {}\n",
    "    # row_data_frame[cat] = []\n",
    "    for i in range(0, len(row_dict[cat])):\n",
    "        filename = row_dict[cat][i]\n",
    "        path = row_doc + cat + \"/\" + filename\n",
    "        with open(path, \"rb\") as f:                \n",
    "            text = f.read()\n",
    "            cat_dict[filename[:3]] = text\n",
    "    row_data[cat] = cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjPzSMPT95Hg"
   },
   "outputs": [],
   "source": [
    "sum_data = {}\n",
    "for cat in sum_dict.keys():\n",
    "    cat_dict = {}\n",
    "    # row_data_frame[cat] = []\n",
    "    for i in range(0, len(sum_dict[cat])):\n",
    "        filename = sum_dict[cat][i]\n",
    "        path = summary_doc + cat + \"/\" + filename\n",
    "        with open(path, \"rb\") as f:                \n",
    "            text = f.read()\n",
    "            cat_dict[filename[:3]] = text\n",
    "    sum_data[cat] = cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-Lr9-hn95Hk",
    "outputId": "081b4cb6-c7a5-4bef-d5c2-a699865a411e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(row_data[\"business\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55_u6rnl95Hq"
   },
   "outputs": [],
   "source": [
    "sum_data[\"business\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "du70GJ7o95H0",
    "outputId": "2f05e596-129f-489e-8fcd-e789f870fe9e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>b'EU-US seeking deal on air dispute\\n\\nThe EU ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>b'US to rule on Yukos refuge call\\n\\nYukos has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>b'India power shares jump on debut\\n\\nShares i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>b'Markets signal Brazilian recovery\\n\\nThe Bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>b\"Reliance unit loses Anil Ambani\\n\\nAnil Amba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           row_article\n",
       "424  b'EU-US seeking deal on air dispute\\n\\nThe EU ...\n",
       "299  b'US to rule on Yukos refuge call\\n\\nYukos has...\n",
       "276  b'India power shares jump on debut\\n\\nShares i...\n",
       "272  b'Markets signal Brazilian recovery\\n\\nThe Bra...\n",
       "379  b\"Reliance unit loses Anil Ambani\\n\\nAnil Amba..."
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_business = pd.DataFrame.from_dict(row_data[\"business\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKbrhIYw95H8"
   },
   "outputs": [],
   "source": [
    "#  news_category = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
    "news_entertainment = pd.DataFrame.from_dict(row_data[\"entertainment\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_politics = pd.DataFrame.from_dict(row_data[\"politics\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_sport = pd.DataFrame.from_dict(row_data[\"sport\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_tech = pd.DataFrame.from_dict(row_data[\"tech\"], orient=\"index\", columns=[\"row_article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrSmXmON95IE"
   },
   "outputs": [],
   "source": [
    "# summary data\n",
    "summary_business = pd.DataFrame.from_dict(sum_data[\"business\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_entertainment = pd.DataFrame.from_dict(sum_data[\"entertainment\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_politics = pd.DataFrame.from_dict(sum_data[\"politics\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_sport = pd.DataFrame.from_dict(sum_data[\"sport\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_tech = pd.DataFrame.from_dict(sum_data[\"tech\"], orient=\"index\", columns=[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNL3-2xL95IJ",
    "outputId": "8dd40f58-2921-4c73-fd62-6b5b9e673169"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>b'Both sides hope to reach a negotiated deal o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>b'Yukos has said a US bankruptcy court will de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>b'Shares in India\\'s largest power producer, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>b\"Investors have praised his handling of the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>b\"Anil, 45, has stepped down as director and v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               summary\n",
       "424  b'Both sides hope to reach a negotiated deal o...\n",
       "299  b'Yukos has said a US bankruptcy court will de...\n",
       "276  b'Shares in India\\'s largest power producer, N...\n",
       "272  b\"Investors have praised his handling of the e...\n",
       "379  b\"Anil, 45, has stepped down as director and v..."
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aq407qkG95IO"
   },
   "outputs": [],
   "source": [
    "business = news_business.join(summary_business, how='inner')\n",
    "entertainment = news_entertainment.join(summary_entertainment, how='inner')\n",
    "politics = news_politics.join(summary_politics, how='inner')\n",
    "sport = news_sport.join(summary_sport, how='inner')\n",
    "tech = news_tech.join(summary_tech, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKbjkn-r95IR"
   },
   "outputs": [],
   "source": [
    "business = news_business.join(summary_business, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKfHtKbL95IW",
    "outputId": "11b33d28-b909-4924-8e97-3e978c473fe8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>b'EU-US seeking deal on air dispute\\n\\nThe EU ...</td>\n",
       "      <td>b'Both sides hope to reach a negotiated deal o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>b'US to rule on Yukos refuge call\\n\\nYukos has...</td>\n",
       "      <td>b'Yukos has said a US bankruptcy court will de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>b'India power shares jump on debut\\n\\nShares i...</td>\n",
       "      <td>b'Shares in India\\'s largest power producer, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>b'Markets signal Brazilian recovery\\n\\nThe Bra...</td>\n",
       "      <td>b\"Investors have praised his handling of the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>b\"Reliance unit loses Anil Ambani\\n\\nAnil Amba...</td>\n",
       "      <td>b\"Anil, 45, has stepped down as director and v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           row_article  \\\n",
       "424  b'EU-US seeking deal on air dispute\\n\\nThe EU ...   \n",
       "299  b'US to rule on Yukos refuge call\\n\\nYukos has...   \n",
       "276  b'India power shares jump on debut\\n\\nShares i...   \n",
       "272  b'Markets signal Brazilian recovery\\n\\nThe Bra...   \n",
       "379  b\"Reliance unit loses Anil Ambani\\n\\nAnil Amba...   \n",
       "\n",
       "                                               summary  \n",
       "424  b'Both sides hope to reach a negotiated deal o...  \n",
       "299  b'Yukos has said a US bankruptcy court will de...  \n",
       "276  b'Shares in India\\'s largest power producer, N...  \n",
       "272  b\"Investors have praised his handling of the e...  \n",
       "379  b\"Anil, 45, has stepped down as director and v...  "
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sUHqLUJ95Ib",
    "outputId": "7b492210-e0b1-4622-fcba-9c0f730ca3cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 2179\n",
      "sum 984\n"
     ]
    }
   ],
   "source": [
    "print(\"row\", len(business.iloc[0,0]))\n",
    "print(\"sum\", len(business.iloc[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VthiJz-h95Ij"
   },
   "outputs": [],
   "source": [
    "list_df = [business, entertainment, politics, sport, tech]\n",
    "length = 0\n",
    "for df in list_df:\n",
    "    length += len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj44ZFO-95Iu",
    "outputId": "f5649126-2cf2-45ad-cc77-879985450f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all data:  2225\n"
     ]
    }
   ],
   "source": [
    "print(\"length of all data: \", length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFtKW1DS95I2",
    "outputId": "f9e46aae-aa16-4415-8302-ddd47bd220ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df = pd.concat([business, entertainment, politics, sport, tech], ignore_index=True)\n",
    "len(bbc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xogCv95T95JF"
   },
   "source": [
    "## Step 2. Preprocessing Text Data\n",
    "1. Clean Text\n",
    "2. Tokenize\n",
    "3. Vocabrary\n",
    "4. Padding\n",
    "5. One-Hot Encoding\n",
    "6. Reshape to (MAX_LEN, One-Hot Encoding DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2un_KkA95JU"
   },
   "source": [
    "### 2-1. Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxQY2wvq95JJ"
   },
   "outputs": [],
   "source": [
    "def cleantext(text):\n",
    "    text = str(text)\n",
    "    text=text.split()\n",
    "    words=[]\n",
    "    for t in text:\n",
    "        if t.isalpha():\n",
    "            words.append(t)\n",
    "    text=\" \".join(words)\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"what's\",\"what is \",text)\n",
    "    text=re.sub(r\"it's\",\"it is \",text)\n",
    "    text=re.sub(r\"\\'ve\",\" have \",text)\n",
    "    text=re.sub(r\"i'm\",\"i am \",text)\n",
    "    text=re.sub(r\"\\'re\",\" are \",text)\n",
    "    text=re.sub(r\"n't\",\" not \",text)\n",
    "    text=re.sub(r\"\\'d\",\" would \",text)\n",
    "    text=re.sub(r\"\\'s\",\"s\",text)\n",
    "    text=re.sub(r\"\\'ll\",\" will \",text)\n",
    "    text=re.sub(r\"can't\",\" cannot \",text)\n",
    "    text=re.sub(r\" e g \",\" eg \",text)\n",
    "    text=re.sub(r\"e-mail\",\"email\",text)\n",
    "    text=re.sub(r\"9\\\\/11\",\" 911 \",text)\n",
    "    text=re.sub(r\" u.s\",\" american \",text)\n",
    "    text=re.sub(r\" u.n\",\" united nations \",text)\n",
    "    text=re.sub(r\"\\n\",\" \",text)\n",
    "    text=re.sub(r\":\",\" \",text)\n",
    "    text=re.sub(r\"-\",\" \",text)\n",
    "    text=re.sub(r\"\\_\",\" \",text)\n",
    "    text=re.sub(r\"\\d+\",\" \",text)\n",
    "    text=re.sub(r\"[$#@%&*!~?%{}()]\",\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7ovvCt495JL"
   },
   "outputs": [],
   "source": [
    "for col in bbc_df.columns:\n",
    "    bbc_df[col] = bbc_df[col].apply(lambda x: cleantext(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwbxBACO95JP",
    "outputId": "8b9cf24a-1714-47bf-944b-4aaa54ab78c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seeking deal on air eu and us have agreed to b...</td>\n",
       "      <td>sides hope to reach a negotiated deal over sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to rule on yukos refuge has said a us bankrupt...</td>\n",
       "      <td>has said a us bankruptcy court will decide whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>power shares jump on in largest power national...</td>\n",
       "      <td>in largest power national thermal power corp h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>signal brazilian brazilian stock market has ri...</td>\n",
       "      <td>have praised his handling of the economy as fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unit loses anil the younger of the two brother...</td>\n",
       "      <td>has stepped down as director and of indian pet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         row_article  \\\n",
       "0  seeking deal on air eu and us have agreed to b...   \n",
       "1  to rule on yukos refuge has said a us bankrupt...   \n",
       "2  power shares jump on in largest power national...   \n",
       "3  signal brazilian brazilian stock market has ri...   \n",
       "4  unit loses anil the younger of the two brother...   \n",
       "\n",
       "                                             summary  \n",
       "0  sides hope to reach a negotiated deal over sta...  \n",
       "1  has said a us bankruptcy court will decide whe...  \n",
       "2  in largest power national thermal power corp h...  \n",
       "3  have praised his handling of the economy as fo...  \n",
       "4  has stepped down as director and of indian pet...  "
      ]
     },
     "execution_count": 168,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "JBPbkd8pIORs",
    "outputId": "51066e27-b9c1-467e-845a-b162e813ce2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continues rapid economy has expanded by a brea...</td>\n",
       "      <td>overall investment in fixed assets was still u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deccan seals deccan has ordered airbus planes ...</td>\n",
       "      <td>government has given its backing to cheaper an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job growth continues in us created fewer jobs ...</td>\n",
       "      <td>creation was one of last main concerns for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owner buys rival for retail giant federated de...</td>\n",
       "      <td>retail giant federated department stores is to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>secures giant japan is to supply japan airline...</td>\n",
       "      <td>chose the after carefully considering both it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         row_article  \\\n",
       "0  continues rapid economy has expanded by a brea...   \n",
       "1  deccan seals deccan has ordered airbus planes ...   \n",
       "2  job growth continues in us created fewer jobs ...   \n",
       "3  owner buys rival for retail giant federated de...   \n",
       "4  secures giant japan is to supply japan airline...   \n",
       "\n",
       "                                             summary  \n",
       "0  overall investment in fixed assets was still u...  \n",
       "1  government has given its backing to cheaper an...  \n",
       "2  creation was one of last main concerns for the...  \n",
       "3  retail giant federated department stores is to...  \n",
       "4  chose the after carefully considering both it ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YA9tvTPUIciB",
    "outputId": "1780794c-4748-49ba-8669-c75b875347d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3807"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list =[]\n",
    "for article in articles:\n",
    "    words = article.split()\n",
    "    length = len(words)\n",
    "    len_list.append(length)\n",
    "max(len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. A wrong way of tokenization: text_to_word_sequence & one_hot method\n",
    "1. Tokenize: text_to_word_sequence \n",
    "2. Cut off word more than max_len 1000\n",
    "3. Padding: pad_sequences\n",
    "4. One-Hot Vectrizer: dimention is under vocab_size\n",
    "5. Reshape: manual max_len * one-Hot matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-1. Tokenize: text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kA8WRa1IIcfY"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def text2seq(text):\n",
    "    seq = text_to_word_sequence(text)\n",
    "    return seq\n",
    "\n",
    "article_sequences = []\n",
    "for article in articles:\n",
    "    seq = text2seq(article)\n",
    "    article_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "TqNrJ4q3CgVN",
    "outputId": "a387f1dd-1d41-4236-86ea-194a6484ea8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['continues',\n",
       " 'rapid',\n",
       " 'economy',\n",
       " 'has',\n",
       " 'expanded',\n",
       " 'by',\n",
       " 'a',\n",
       " 'breakneck',\n",
       " 'during',\n",
       " 'faster']"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sequences[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_P2YDoRLmzfp"
   },
   "outputs": [],
   "source": [
    "sum_sequences = []\n",
    "for summary in summaries:\n",
    "    seq = text2seq(summary)\n",
    "    sum_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "EZXziugpCmun",
    "outputId": "cf515056-8119-4f2b-b7e7-4c9a63310f91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['overall',\n",
       " 'investment',\n",
       " 'in',\n",
       " 'fixed',\n",
       " 'assets',\n",
       " 'was',\n",
       " 'still',\n",
       " 'up',\n",
       " 'from',\n",
       " 'the']"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_sequences[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "365SOE_-n23i",
    "outputId": "e208928c-a54b-492b-9b7f-e77edf8aa04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 1822\n",
      "min 28\n",
      "ave 125.866\n"
     ]
    }
   ],
   "source": [
    "sum_len = []\n",
    "for i in range(1000):\n",
    "    sum_len.append(len(sum_sequences[i]))\n",
    "print(\"max\", max(sum_len))\n",
    "print(\"min\", min(sum_len))\n",
    "print(\"ave\", sum(sum_len)/len(sum_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "gILq_p9N-zfl",
    "outputId": "d757f42e-708b-4540-905a-3bc9318a0b24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 3693\n",
      "min 75\n",
      "ave 279.943\n"
     ]
    }
   ],
   "source": [
    "art_len = []\n",
    "for i in range(1000):\n",
    "    art_len.append(len(article_sequences[i]))\n",
    "print(\"max\", max(art_len))\n",
    "print(\"min\", min(art_len))\n",
    "print(\"ave\", sum(art_len)/len(art_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rljhCnJo_D3Q",
    "outputId": "19b3c204-6caf-4efa-c9fa-210b78c5f1b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['government', 'has', 'given', 'its', 'backing', 'to']"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_sequences[1][:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-2. Cut off word more than max_len 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRcpQJKkrtTA"
   },
   "outputs": [],
   "source": [
    "max_1000_art_sequences = []\n",
    "for sequences in article_sequences:\n",
    "    if len(sequences) > 1000:\n",
    "        sequences = sequences[:1000]\n",
    "    max_1000_art_sequences.append(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "iihzbBGiTfxB",
    "outputId": "67b6dade-c6ac-4eee-c642-7bdef75d54cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 1000\n",
      "min 75\n",
      "ave 273.675\n"
     ]
    }
   ],
   "source": [
    "art_len = []\n",
    "for i in range(1000):\n",
    "    art_len.append(len(max_1000_art_sequences[i]))\n",
    "print(\"max\", max(art_len))\n",
    "print(\"min\", min(art_len))\n",
    "print(\"ave\", sum(art_len)/len(art_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_Bj-VFKASCK"
   },
   "outputs": [],
   "source": [
    "max_1000_sum_sequences = []\n",
    "for sequences in sum_sequences:\n",
    "    if len(sequences) > 1000:\n",
    "        sequences = sequences[:1000]\n",
    "    max_1000_sum_sequences.append(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "n94MtgJrAR8y",
    "outputId": "48202215-bd9f-4cb1-aca3-0f3a57561017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 1000\n",
      "min 28\n",
      "ave 124.594\n"
     ]
    }
   ],
   "source": [
    "sum_len = []\n",
    "for i in range(1000):\n",
    "    sum_len.append(len(max_1000_sum_sequences[i]))\n",
    "print(\"max\", max(sum_len))\n",
    "print(\"min\", min(sum_len))\n",
    "print(\"ave\", sum(sum_len)/len(sum_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-3. Padding: pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfEa2upSBA2A"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 1000\n",
    "padded_art_sequences = pad_sequences(max_1000_art_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "tNhauF4gBAyO",
    "outputId": "829b62b6-c2c5-43f6-cf71-efff689e4d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(padded_art_sequences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "2DZIBbKOCA7f",
    "outputId": "da4e0cc5-3be5-4c92-c065-447c860c9f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1411, 2338,  248,   16, 3994,   22,    5, 6483,  165, 1359],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_art_sequences[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oslqftw_BAuL"
   },
   "outputs": [],
   "source": [
    "padded_sum_sequences = pad_sequences(max_1000_sum_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SGWkMY2xU9-n",
    "outputId": "8d3d54d9-d2f2-4766-8ee7-5a26658e4867"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23690"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_vocab = []\n",
    "for seqs in max_1000_art_sequences:\n",
    "    for seq in seqs:\n",
    "        if seq not in art_vocab:\n",
    "            art_vocab.append(seq)\n",
    "len(art_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EZmkurFRmS4M",
    "outputId": "d606e1ca-be6b-42a0-ad14-03c30c153f3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16417"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_vocab = []\n",
    "for seqs in max_1000_sum_sequences:\n",
    "    for seq in seqs:\n",
    "        if seq not in sum_vocab:\n",
    "        sum_vocab.append(seq)\n",
    "len(sum_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-4. One-Hot Vectrizer: dimention is under vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xDWnebYGE5cZ"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "VOCAB_SIZE = 14999 # paddingするから\n",
    "one_hot_art_sequences = []\n",
    "for seqs in max_1000_art_sequences:\n",
    "    text = \" \".join(seqs)\n",
    "    one_hot_text = one_hot(text, n=VOCAB_SIZE)\n",
    "    one_hot_art_sequences.append(one_hot_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "BwV4y_SyFx1l",
    "outputId": "fab2b064-86b5-4da2-d5f7-ab0af6a58862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10891, 7320, 7007, 1008, 5342, 1787, 12034, 11065, 13980, 11281, 14867, 12784]\n",
      "[11929, 14009, 11929, 1008, 10641, 11421, 6113, 7521, 12034, 5496, 8576, 11688]\n",
      "[10689, 5411, 10891, 7521, 7461, 13619, 14706, 5896, 14867, 13469, 7521, 1221]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_art_sequences[0][:12])\n",
    "print(one_hot_art_sequences[1][:12])\n",
    "print(one_hot_art_sequences[2][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "VW0BozPIFxx2",
    "outputId": "5386c729-94c5-4ec2-cce9-e1a706120fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "248\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "print(len(one_hot_art_sequences[0]))\n",
    "print(len(one_hot_art_sequences[1]))\n",
    "print(len(one_hot_art_sequences[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tj5q9GicGHwi"
   },
   "outputs": [],
   "source": [
    "one_hot_sum_sequences = []\n",
    "for seqs in max_1000_sum_sequences:\n",
    "  text = \" \".join(seqs)\n",
    "  one_hot_text = one_hot(text, n=VOCAB_SIZE)\n",
    "  one_hot_sum_sequences.append(one_hot_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "j4B_zvAHGHtP",
    "outputId": "5c2e9929-cbd5-4627-a863-8f61c5cd9e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4512, 10484, 7521, 10822, 8048, 11626, 8375, 4699, 9453, 9966, 14537, 14349]\n",
      "[3878, 1008, 13510, 7408, 7221, 10056, 8820, 14829, 3157, 9038, 2291, 3170]\n",
      "[1477, 11626, 9763, 1380, 9090, 9060, 835, 14461, 9966, 7461, 1477, 11626]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_sum_sequences[0][:12])\n",
    "print(one_hot_sum_sequences[1][:12])\n",
    "print(one_hot_sum_sequences[2][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cHqN2WDHh2M"
   },
   "outputs": [],
   "source": [
    "for seqs in one_hot_sum_sequences:\n",
    "  for seq in seqs:\n",
    "    if seq == 0:\n",
    "      print(\"OMG!\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkBd47DpGHo5"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 1000\n",
    "padded_onehot_art_sequences = pad_sequences(one_hot_art_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "N4pOXCrSGHlV",
    "outputId": "300481be-d869-4edb-c4ed-ad1adbfb5ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(padded_onehot_art_sequences[0]))\n",
    "print(len(padded_onehot_art_sequences[1]))\n",
    "print(len(padded_onehot_art_sequences[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwYaqef1Gx5Z"
   },
   "outputs": [],
   "source": [
    "padded_onehot_sum_sequences = pad_sequences(one_hot_sum_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "9RBKcoeFGyFy",
    "outputId": "e8429edb-6624-4acb-83f4-0dbd93b144cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(padded_onehot_sum_sequences[0]))\n",
    "print(len(padded_onehot_sum_sequences[1]))\n",
    "print(len(padded_onehot_sum_sequences[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "je8zITucGySK"
   },
   "outputs": [],
   "source": [
    "padded_onehot_sum_sequences[1][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlFMOxIZGyb9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "padded_onehot_summary_sequences = pd.DataFrame(padded_onehot_sum_sequences) \n",
    "padded_onehot_summary_sequences.to_csv(\"padded_onehot_sum_sequences.csv\")\n",
    "from google.colab import files\n",
    "files.download('padded_onehot_sum_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjGk4KhWGyoI"
   },
   "outputs": [],
   "source": [
    "padded_onehot_article_sequences = pd.DataFrame(padded_onehot_art_sequences) \n",
    "padded_onehot_article_sequences.to_csv(\"padded_onehot_art_sequences.csv\")\n",
    "from google.colab import files\n",
    "files.download('padded_onehot_art_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdgG2rulGj_t"
   },
   "outputs": [],
   "source": [
    "# Code to read csv file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKzgWqESGluy"
   },
   "outputs": [],
   "source": [
    "link = \"https://drive.google.com/open?id=1SiYY-f38JTY_x7xPZM751PoLgIqH--qz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q7XK8jiFGl3-",
    "outputId": "bb3d6b94-3636-4e6f-c810-1152602b63e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1SiYY-f38JTY_x7xPZM751PoLgIqH--qz\n"
     ]
    }
   ],
   "source": [
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAx9rAwdOZrZ"
   },
   "outputs": [],
   "source": [
    "link = \"https://drive.google.com/open?id=1zkdrg5pq_s5Skynjk3X0GSkp-B2-rB7T\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hhHf937KOZmJ",
    "outputId": "71ef492c-8116-4d27-feb2-2408d98e84e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1zkdrg5pq_s5Skynjk3X0GSkp-B2-rB7T\n"
     ]
    }
   ],
   "source": [
    "fluff, id = link.split('=')\n",
    "print (id) # Verify that you have everything after '='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "ALTz8xn-OZfZ",
    "outputId": "608665e2-065b-4998-ca2c-81cbda160847"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4512</td>\n",
       "      <td>10484</td>\n",
       "      <td>7521</td>\n",
       "      <td>10822</td>\n",
       "      <td>8048</td>\n",
       "      <td>11626</td>\n",
       "      <td>8375</td>\n",
       "      <td>4699</td>\n",
       "      <td>9453</td>\n",
       "      <td>9966</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3878</td>\n",
       "      <td>1008</td>\n",
       "      <td>13510</td>\n",
       "      <td>7408</td>\n",
       "      <td>7221</td>\n",
       "      <td>10056</td>\n",
       "      <td>8820</td>\n",
       "      <td>14829</td>\n",
       "      <td>3157</td>\n",
       "      <td>9038</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1477</td>\n",
       "      <td>11626</td>\n",
       "      <td>9763</td>\n",
       "      <td>1380</td>\n",
       "      <td>9090</td>\n",
       "      <td>9060</td>\n",
       "      <td>835</td>\n",
       "      <td>14461</td>\n",
       "      <td>9966</td>\n",
       "      <td>7461</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8095</td>\n",
       "      <td>13136</td>\n",
       "      <td>14278</td>\n",
       "      <td>13695</td>\n",
       "      <td>9862</td>\n",
       "      <td>982</td>\n",
       "      <td>10056</td>\n",
       "      <td>12786</td>\n",
       "      <td>12870</td>\n",
       "      <td>7150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14037</td>\n",
       "      <td>9966</td>\n",
       "      <td>10824</td>\n",
       "      <td>9640</td>\n",
       "      <td>4372</td>\n",
       "      <td>10364</td>\n",
       "      <td>3170</td>\n",
       "      <td>14829</td>\n",
       "      <td>9202</td>\n",
       "      <td>12034</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3     4      5      6      7      8      9 ...   \\\n",
       "0   4512  10484   7521  10822  8048  11626   8375   4699   9453   9966 ...    \n",
       "1   3878   1008  13510   7408  7221  10056   8820  14829   3157   9038 ...    \n",
       "2   1477  11626   9763   1380  9090   9060    835  14461   9966   7461 ...    \n",
       "3   8095  13136  14278  13695  9862    982  10056  12786  12870   7150 ...    \n",
       "4  14037   9966  10824   9640  4372  10364   3170  14829   9202  12034 ...    \n",
       "\n",
       "   990  991  992  993  994  995  996  997  998  999  \n",
       "0    0    0    0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('padded_onehot_sum_sequences.csv')\n",
    "sum_df = pd.read_csv('padded_onehot_sum_sequences.csv')\n",
    "sum_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FL7FdAV695OJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('padded_onehot_art_sequences.csv')\n",
    "ar_ticle_df = pd.read_csv('padded_onehot_art_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "XV0aYBxhOMzy",
    "outputId": "9a3abda0-fbfd-4201-f5f9-e8372466e3fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10891</td>\n",
       "      <td>7320</td>\n",
       "      <td>7007</td>\n",
       "      <td>1008</td>\n",
       "      <td>5342</td>\n",
       "      <td>1787</td>\n",
       "      <td>12034</td>\n",
       "      <td>11065</td>\n",
       "      <td>13980</td>\n",
       "      <td>11281</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11929</td>\n",
       "      <td>14009</td>\n",
       "      <td>11929</td>\n",
       "      <td>1008</td>\n",
       "      <td>10641</td>\n",
       "      <td>11421</td>\n",
       "      <td>6113</td>\n",
       "      <td>7521</td>\n",
       "      <td>12034</td>\n",
       "      <td>5496</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10689</td>\n",
       "      <td>5411</td>\n",
       "      <td>10891</td>\n",
       "      <td>7521</td>\n",
       "      <td>7461</td>\n",
       "      <td>13619</td>\n",
       "      <td>14706</td>\n",
       "      <td>5896</td>\n",
       "      <td>14867</td>\n",
       "      <td>13469</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9296</td>\n",
       "      <td>3698</td>\n",
       "      <td>12870</td>\n",
       "      <td>14461</td>\n",
       "      <td>8095</td>\n",
       "      <td>13136</td>\n",
       "      <td>14278</td>\n",
       "      <td>13695</td>\n",
       "      <td>9862</td>\n",
       "      <td>982</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9853</td>\n",
       "      <td>13136</td>\n",
       "      <td>13847</td>\n",
       "      <td>982</td>\n",
       "      <td>10056</td>\n",
       "      <td>8984</td>\n",
       "      <td>13847</td>\n",
       "      <td>145</td>\n",
       "      <td>1187</td>\n",
       "      <td>4699</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9 ...   \\\n",
       "0  10891   7320   7007   1008   5342   1787  12034  11065  13980  11281 ...    \n",
       "1  11929  14009  11929   1008  10641  11421   6113   7521  12034   5496 ...    \n",
       "2  10689   5411  10891   7521   7461  13619  14706   5896  14867  13469 ...    \n",
       "3   9296   3698  12870  14461   8095  13136  14278  13695   9862    982 ...    \n",
       "4   9853  13136  13847    982  10056   8984  13847    145   1187   4699 ...    \n",
       "\n",
       "   990  991  992  993  994  995  996  997  998  999  \n",
       "0    0    0    0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ticle_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "ar_ticle_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWzk3ldNumU5"
   },
   "source": [
    "#### 2-2-5. Reshape: manual max_len * one-Hot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "art_df = pd.read_csv(\"padded_onehot_art_sequences.csv\")\n",
    "sum_df = pd.read_csv(\"padded_onehot_sum_sequences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "sum_df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_flelx7PE2x"
   },
   "outputs": [],
   "source": [
    "sum_list = []\n",
    "for i in range(len(sum_df)):\n",
    "    sum_list.append(sum_df.iloc[i].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lQjckvJkQqLT",
    "outputId": "13d08d99-16f9-41a0-9f21-c365a144c21d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4512, 10484, 7521, 10822, 8048]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_list[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nS71MWvlQqGT"
   },
   "outputs": [],
   "source": [
    "art_list = []\n",
    "for i in range(len(art_df)):\n",
    "    art_list.append(art_df.iloc[i].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IC7mcRTrRKGe",
    "outputId": "2e5cf360-20dc-4546-d3d2-9790799d45b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_list[1][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rd1bJK_-Vq2m",
    "outputId": "c6237073-b77e-4577-9951-e754d23a8115"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(art_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XkqF8AhJP_4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000, 15000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "art_matrix = np.zeros((2225, 1000, 15000), dtype='float32')\n",
    "art_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJT7BeSiZf9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000, 15000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_matrix = np.zeros((2225, 1000, 15000), dtype='float32')\n",
    "sum_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3D input data (samples, maxlen, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YarjgDJXhj1"
   },
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(art_list):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        art_matrix[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Sv2fXo3ZWrP"
   },
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(sum_list):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        sum_matrix[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2D input data (maxlen, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs = np.zeros((2225, 1000), dtype='float32')\n",
    "encoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs = np.zeros((2225, 1000), dtype='float32')\n",
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(art_list):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        encoder_inputs[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(sum_list):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_inputs[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4512., 10484.,  7521., ...,     0.,     0.,     0.],\n",
       "       [ 3878.,  1008., 13510., ...,     0.,     0.,     0.],\n",
       "       [ 1477., 11626.,  9763., ...,     0.,     0.,     0.],\n",
       "       ...,\n",
       "       [13064.,   982., 13178., ...,     0.,     0.,     0.],\n",
       "       [14971., 13573., 11792., ...,     0.,     0.,     0.],\n",
       "       [10056.,  9966.,  3527., ...,     0.,     0.,     0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgiKHJJJJP3J"
   },
   "source": [
    "##  I found.... 辞書作らないとだめや！\n",
    "![](https://images.unsplash.com/photo-1486002113024-43b2ce358eb0?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1072&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jO14nm8JJPzZ"
   },
   "source": [
    "### 2-2. B right way of tokenization: Tokenizer\n",
    "1. Tokenize and One-Hot : Tokenizer\n",
    "2. Vocabraly: article and summary 15000 words \n",
    "3. Padding: pad_sequences 1000 max_len\n",
    "4. Reshape: manual max_len * one-hot matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continues rapid economy has expanded by a brea...</td>\n",
       "      <td>overall investment in fixed assets was still u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deccan seals deccan has ordered airbus planes ...</td>\n",
       "      <td>government has given its backing to cheaper an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job growth continues in us created fewer jobs ...</td>\n",
       "      <td>creation was one of last main concerns for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owner buys rival for retail giant federated de...</td>\n",
       "      <td>retail giant federated department stores is to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>secures giant japan is to supply japan airline...</td>\n",
       "      <td>chose the after carefully considering both it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         row_article  \\\n",
       "0  continues rapid economy has expanded by a brea...   \n",
       "1  deccan seals deccan has ordered airbus planes ...   \n",
       "2  job growth continues in us created fewer jobs ...   \n",
       "3  owner buys rival for retail giant federated de...   \n",
       "4  secures giant japan is to supply japan airline...   \n",
       "\n",
       "                                             summary  \n",
       "0  overall investment in fixed assets was still u...  \n",
       "1  government has given its backing to cheaper an...  \n",
       "2  creation was one of last main concerns for the...  \n",
       "3  retail giant federated department stores is to...  \n",
       "4  chose the after carefully considering both it ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_art_sum = pd.read_csv(\"cleaned_bbc_news.csv\")\n",
    "bbc_art_sum.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "bbc_art_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = list(bbc_art_sum.row_article)\n",
    "summaries = list(bbc_art_sum.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1. Tokenize: text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W9aALHY_YbUN",
    "outputId": "b228cf03-c36b-413a-d3c8-c9cb6fff1b36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23914"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "VOCAB_SIZE = 14999\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(articles)\n",
    "article_sequences = tokenizer.texts_to_sequences(articles)\n",
    "art_word_index = tokenizer.word_index\n",
    "len(art_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1411, 2338, 248, 16, 3994, 22, 5, 6483, 165, 1359, 50, 966, 4, 120, 967, 176, 118, 505, 38, 2339]\n",
      "[5211, 8881, 5211, 16, 2233, 3001, 3441, 6, 5, 217, 18, 60, 1270, 7874, 6, 1, 827, 5211, 11, 108]\n",
      "[478, 196, 1411, 6, 54, 736, 2283, 498, 50, 164, 6, 24, 349, 17, 9, 1, 3322, 6, 5213, 11]\n"
     ]
    }
   ],
   "source": [
    "print(article_sequences[0][:20])\n",
    "print(article_sequences[1][:20])\n",
    "print(article_sequences[2][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2. Vocabraly: article and summary 15000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_word_index_1500 = {}\n",
    "counter = 0\n",
    "for word in art_word_index.keys():\n",
    "    if art_word_index[word] == 0:\n",
    "        print(\"found 0!\")\n",
    "        break\n",
    "    if art_word_index[word] > VOCAB_SIZE:\n",
    "        continue\n",
    "    else:\n",
    "        art_word_index_1500[word] = art_word_index[word]\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14999"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23929"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(summaries)\n",
    "summary_sequences = tokenizer.texts_to_sequences(summaries)\n",
    "sum_word_index = tokenizer.word_index\n",
    "len(sum_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_word_index_1500 = {}\n",
    "counter = 0\n",
    "for word in sum_word_index.keys():\n",
    "    if sum_word_index[word] == 0:\n",
    "        print(\"found 0!\")\n",
    "        break\n",
    "    if sum_word_index[word] > VOCAB_SIZE:\n",
    "        continue\n",
    "    else:\n",
    "        sum_word_index_1500[word] = sum_word_index[word]\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14999"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3. Padding: pad_sequences 1000 max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 1000\n",
    "pad_art_sequences = pad_sequences(article_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(article_sequences[1]), len(pad_art_sequences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sum_sequences = pad_sequences(summary_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(summary_sequences[1]), len(pad_sum_sequences[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-4. Reshape: manual max_len * one-hot matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reshape in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000, 15000)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "art_matrix = np.zeros((2225, 1000, 15000), dtype='float32')\n",
    "art_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_art_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        art_matrix[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_matrix[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_matrix = np.zeros((2225, 1000, 15000), dtype='float32')\n",
    "\n",
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        sum_matrix[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sum_matrix[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sum_matrix[1, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Reshape in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs = np.zeros((2225, 1000), dtype='float32')\n",
    "encoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs = np.zeros((2225, 1000), dtype='float32')\n",
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000, 15000)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs = np.zeros((2225, 1000, 15000), dtype='float32')\n",
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_art_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        encoder_inputs[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_inputs[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_outputs[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000, 15000)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reshape in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 15000)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs2D = np.zeros((1000, 15000), dtype='float32')\n",
    "encoder_inputs2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 15000)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs2D = np.zeros((1000, 15000), dtype='float32')\n",
    "decoder_inputs2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1000 is out of bounds for axis 0 with size 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-644e0aea49af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_art_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mencoder_inputs2D\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1000 is out of bounds for axis 0 with size 1000"
     ]
    }
   ],
   "source": [
    "for i, seqs in enumerate(pad_art_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        encoder_inputs2D[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_inputs2D[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-5. Pre-trained word2vec and word2vec Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sokvMj0Xfnjw",
    "outputId": "3ef40349-e3e7-4f25-d263-7d316d21f829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.200d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdx3r2rvZAwN"
   },
   "outputs": [],
   "source": [
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VB6UmXeqWleO",
    "outputId": "59e76cc0-91a2-454b-a61e-f7cb1b2cf59a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 200)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_embedding_matrix = embedding_matrix_creater(200, word_index=art_word_index_1500)\n",
    "art_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1KgrdRFvb7A1",
    "outputId": "e01036f5-476b-46eb-bec7-1ad263ba9dd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 200)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_embedding_matrix = embedding_matrix_creater(200, word_index=sum_word_index_1500)\n",
    "sum_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuawT3rXUIBY"
   },
   "outputs": [],
   "source": [
    "encoder_embedding_layer = Embedding(input_dim = 15000, \n",
    "                                    output_dim = 200,\n",
    "                                    input_length = MAX_LEN,\n",
    "                                    weights = [art_embedding_matrix],\n",
    "                                    trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf3EzUZcIccZ"
   },
   "outputs": [],
   "source": [
    "decoder_embedding_layer = Embedding(input_dim = 15000, \n",
    "                                    output_dim = 200,\n",
    "                                    input_length = MAX_LEN,\n",
    "                                    weights = [sum_embedding_matrix],\n",
    "                                    trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J5acWwCxIcZz",
    "outputId": "a92cd279-b2de-4110-fd1d-35e13e90c099"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 200)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB663AaY0PKH"
   },
   "source": [
    "## Step 3. Building Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-kZT0pQRqRl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pydot\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as k\n",
    "k.set_learning_phase(1)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,LSTM,Dropout,Input,Activation,Add,concatenate, Embedding, RepeatVector\n",
    "from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psWPxabWIcWz"
   },
   "outputs": [],
   "source": [
    "# en_shape = np.shape(train_data[\"article\"][0])\n",
    "# den_shape = np.shape(train_data[\"summaries\"][0])\n",
    "\n",
    "ART_MAX_LEN = 1000\n",
    "SUM_MAX_LEN = 1000\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_UNITS = 200\n",
    "\n",
    "LEARNING_RATE = 0.002\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "# rmsprop = RMSprop(lr=LEARNING_RATE, clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGjWMUG3IcT_"
   },
   "outputs": [],
   "source": [
    "def Recursive_modelA(encoder_embedding_layer, dencoder_embedding_layer):\n",
    "    \"\"\"\n",
    "    Encoder-Decoder-seq2seq\n",
    "    \"\"\"\n",
    "    # encoder\n",
    "    encoder_inputs = Input(shape=(MAX_LEN, ))\n",
    "    encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "    encoder_LSTM = LSTM(200)(encoder_embedding)\n",
    "    \n",
    "    # thought_vector = RepeatVector(SUM_MAX_LEN)(encoder_LSTM)\n",
    "    # rev_encoder_LSTM = LSTM(HIDDEN_UNITS, return_state=True, go_backwards=True)\n",
    "    # \n",
    "    # encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "    # rev_encoder_outputs, rev_state_h, rev_state_c = rev_encoder_LSTM(encoder_embedding)\n",
    "    #\n",
    "    # final_state_h = Add()([state_h, rev_state_h])\n",
    "    # final_state_c = Add()([state_c, rev_state_c])\n",
    "\n",
    "    # encoder_states = [final_state_h, final_state_c]\n",
    "\n",
    "    # decoder\n",
    "    decoder_inputs = Input(shape=(MAX_LEN, ))\n",
    "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "    decoder_LSTM = LSTM(200)(decoder_embedding)\n",
    "    \n",
    "    merge_layer = concatenate([encoder_LSTM, decoder_LSTM])\n",
    "    # decoder_outputs, _, _, = decoder_LSTM(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_outputs = Dense(units=VOCAB_SIZE+1, activation=\"softmax\")(merge_layer) # SUM_VOCAB_SIZE, sum_embedding_matrix.shape[1]\n",
    "    # decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # modeling\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJ0o-e1j4ydC"
   },
   "outputs": [],
   "source": [
    "model = Recursive_modelA(encoder_embedding_layer, decoder_embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "p0WRxdgeIcQp",
    "outputId": "b1d913ee-5584-49dd-cd38-ca6eeae7ea11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 200)    3000000     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1000, 200)    3000000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 200)          320800      embedding_2[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 200)          320800      embedding_3[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 400)          0           lstm_5[0][0]                     \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 15000)        6015000     concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12,656,600\n",
      "Trainable params: 6,656,600\n",
      "Non-trainable params: 6,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pS3ZL68b-hMa"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='RecursiveModelA.png')\n",
    "from google.colab import files\n",
    "files.download('RecursiveModelA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "HV8UITlJ-mTL",
    "outputId": "25710a79-5949-4b93-a661-d800d926d181"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHw0flwp4uW2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Training your model and Validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFxSEKvfIoGf"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(art_matrix, sum_matrix, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9hn_1hm-JCa2",
    "outputId": "95c79153-06ec-4b2d-b25e-6f34c933ae44"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zgJoAwibJCOy",
    "outputId": "8a94a3ef-affe-4a2d-e801-c1aed87ae6e9"
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SRt0Wt4kIods",
    "outputId": "d396a8f5-7629-4ffe-e168-86a4dd9d3608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1780, 1000)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "us6o1MQXIolz"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "9rnVWHpSIoPI",
    "outputId": "1c1f1f50-46dd-436b-f788-7d76717645c2"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_2 to have shape (15000,) but got array with shape (1000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-4a08380bb119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/jupyter3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyter3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/jupyter3/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have shape (15000,) but got array with shape (1000,)"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train, y_train], y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_data=([x_test, y_test], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pm-V-4MiIos7"
   },
   "source": [
    "## Step 5. Inference phase and Generate summary from fuyure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "input_matrix.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
